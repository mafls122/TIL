{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 모델링 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Activation, Conv2D, Flatten, Dense, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2586, 26, 34, 1) (2586, 1)\n",
      "(288, 26, 34, 1) (288, 1)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "x_train = np.load('eye_blink_detector-master/dataset/x_train.npy').astype(np.float32)\n",
    "y_train = np.load('eye_blink_detector-master/dataset/y_train.npy').astype(np.float32)\n",
    "x_val = np.load('eye_blink_detector-master/dataset/x_val.npy').astype(np.float32)\n",
    "y_val = np.load('eye_blink_detector-master/dataset/y_val.npy').astype(np.float32)\n",
    "\n",
    "# 데이터 shape 확인\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 26, 34, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 34, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 17, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               786944    \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 880,129\n",
      "Trainable params: 880,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델링\n",
    "\n",
    "inputs = Input(shape=(26, 34, 1))\n",
    "\n",
    "net = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(inputs)\n",
    "net = MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n",
    "net = MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n",
    "net = MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = Flatten()(net)\n",
    "\n",
    "net = Dense(512)(net)\n",
    "net = Activation('relu')(net)\n",
    "net = Dense(1)(net)\n",
    "outputs = Activation('sigmoid')(net)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='Rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 복제\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "    x=x_train, y=y_train,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow(\n",
    "    x=x_val, y=y_val,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "81/81 [==============================] - 6s 52ms/step - loss: 0.6066 - acc: 0.6351 - val_loss: 0.2136 - val_acc: 0.9062\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90625, saving model to models\\20210301.h5\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 4s 43ms/step - loss: 0.2785 - acc: 0.8943 - val_loss: 0.1137 - val_acc: 0.9792\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.90625 to 0.97917, saving model to models\\20210301.h5\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.2019 - acc: 0.9255 - val_loss: 0.0705 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.97917\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 4s 46ms/step - loss: 0.1595 - acc: 0.9426 - val_loss: 0.1540 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.97917\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 4s 48ms/step - loss: 0.1295 - acc: 0.9565 - val_loss: 0.0355 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.97917 to 0.99306, saving model to models\\20210301.h5\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 4s 44ms/step - loss: 0.1088 - acc: 0.9644 - val_loss: 0.0439 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99306\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 4s 46ms/step - loss: 0.0944 - acc: 0.9722 - val_loss: 0.0300 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99306\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0885 - acc: 0.9761 - val_loss: 0.0256 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.99306 to 0.99653, saving model to models\\20210301.h5\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 4s 46ms/step - loss: 0.0630 - acc: 0.9819 - val_loss: 0.0398 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99653\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0625 - acc: 0.9794 - val_loss: 0.0254 - val_acc: 0.9896\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99653\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 4s 46ms/step - loss: 0.0557 - acc: 0.9818 - val_loss: 0.0185 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99653\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 4s 45ms/step - loss: 0.0578 - acc: 0.9760 - val_loss: 0.0149 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99653\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 4s 45ms/step - loss: 0.0539 - acc: 0.9860 - val_loss: 0.0492 - val_acc: 0.9896\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99653\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 4s 46ms/step - loss: 0.0489 - acc: 0.9830 - val_loss: 0.0193 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99653\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 4s 46ms/step - loss: 0.0463 - acc: 0.9846 - val_loss: 0.0377 - val_acc: 0.9861\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99653\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 4s 45ms/step - loss: 0.0469 - acc: 0.9870 - val_loss: 0.0198 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99653\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0440 - acc: 0.9867 - val_loss: 0.0282 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99653\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0462 - acc: 0.9827 - val_loss: 0.1086 - val_acc: 0.9549\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99653\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 4s 46ms/step - loss: 0.0233 - acc: 0.9936 - val_loss: 0.0223 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99653\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0155 - acc: 0.9931 - val_loss: 0.0172 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2be7c1bc640>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "\n",
    "start_time = '20210301'\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator, epochs=20, validation_data=val_generator,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/%s.h5' % (start_time), monitor='val_acc', save_best_only=True, mode='max', verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=10, verbose=1, mode='auto', min_lr=1e-05)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.9965277777777778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 정확도 측정, 시각화\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "model = load_model('models/%s.h5' % (start_time))\n",
    "\n",
    "y_pred = model.predict(x_val/255.)\n",
    "y_pred_logical = (y_pred > 0.5).astype(np.int)\n",
    "\n",
    "print ('test acc: %s' % accuracy_score(y_val, y_pred_logical))\n",
    "cm = confusion_matrix(y_val, y_pred_logical)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
