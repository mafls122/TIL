{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install tensorboardX\n",
    "pip install jupyter-tensorboard\n",
    "pip install keras\n",
    "pip install h5py\n",
    "pip install tensorflow --user\n",
    "!python -m pip install --upgrade tensorflow --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[12]], shape=(1, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 행과 열 만들기\n",
    "matrix1 = tf.constant( [ [  3, 3  ]   ] )\n",
    "matrix1\n",
    "\n",
    "matrix2 = tf.constant( [ [  2 ] , [2]   ] )\n",
    "matrix2\n",
    "\n",
    "res = tf.matmul(matrix1, matrix2)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "tf.Tensor([[12]], shape=(1, 1), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 1  4]\n",
      " [ 9 16]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[2 4]\n",
      " [6 8]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 행과 열 만들기\n",
    "matrix1 = tf.constant( [ [  3, 3  ]   ] )\n",
    "matrix1\n",
    "\n",
    "matrix2 = tf.constant( [ [  2 ] , [2]   ] )\n",
    "matrix2\n",
    "print(matrix2.shape)  # 2,1\n",
    "\n",
    "res = tf.matmul(matrix1, matrix2)\n",
    "print(res)\n",
    "\n",
    "x = tf.constant(([1,2,3,4]),shape=(2,2))\n",
    "res02 = tf.math.multiply(x,x)\n",
    "print(res02)\n",
    "\n",
    "hap = tf.math.add(x,x)\n",
    "print(hap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([7.], shape=(1,), dtype=float32)\n",
      "tf.Tensor([21.], shape=(1,), dtype=float32)\n",
      "tf.Tensor([21.], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 행열 연산을 구현해보자 -> 3.0 * (2.0 + 5.0)\n",
    "input01 = tf.constant( [ 3.0   ] )\n",
    "input02 = tf.constant( [ 2.0   ] )\n",
    "input03 = tf.constant( [ 5.0   ] )\n",
    "\n",
    "# 1.\n",
    "hap = tf.add(input02, input03)\n",
    "res = tf.multiply(input01,hap)\n",
    "print(hap)\n",
    "print(res)\n",
    "\n",
    "# 2.\n",
    "res02 = tf.multiply( input01, tf.add(input02, input03))\n",
    "print(res02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "hello,[[4]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 기본 실행 메소드 사용\n",
    "print(tf.executing_eagerly())\n",
    "x=[[2]]\n",
    "m = tf.matmul(x,x)\n",
    "print(\"hello,{}\".format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "<class 'numpy.ndarray'>\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
      "array([[1, 2],\n",
      "       [3, 4]])>> \n",
      "\n",
      "(2, 2)\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "# 반환 작업\n",
    "a = tf.constant([[1,2],[3,4]])\n",
    "print(a.numpy()) # 메소드\n",
    "print(type(a.numpy()))\n",
    "print(a.numpy,'\\n') # 속성\n",
    "print(a.shape)\n",
    "print(a)\n",
    "print(a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 2  6]\n",
      " [12 20]], shape=(2, 2), dtype=int32)\n",
      "[[ 2  6]\n",
      " [12 20]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# 브로드캐스팅(Broadcasting) 지원\n",
    "b = tf.add(a,1)\n",
    "print(b)\n",
    "\n",
    "# 연산자 오버로딩 지원\n",
    "print(a*b)\n",
    "\n",
    "# numpy 지원\n",
    "import numpy as np\n",
    "\n",
    "res = np.multiply(a,b)\n",
    "print(res, type(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(150, shape=(), dtype=int32)\n",
      "150\n",
      "b'\\xec\\xa3\\xbc\\xec\\x95\\x84'\n"
     ]
    }
   ],
   "source": [
    "# Variable : 변수 자동 변환\n",
    "\n",
    "name = tf.Variable('주아', tf.string)\n",
    "kor = tf.Variable(100, tf.int32)\n",
    "eng = tf.Variable(50, tf.int32)\n",
    "tot = kor + eng\n",
    "print(tot)\n",
    "print(tot.numpy())\n",
    "\n",
    "print(name.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   3.    256.   1234.56]\n",
      "<dtype: 'float32'>\n",
      "[1 2 3 4 5]\n",
      "[12.3-4.85j  7.5-6.12j]\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable( [3, 256, 1234.56], tf.float32 )\n",
    "b = tf.Variable([1,2,3,4,5], tf.float32)\n",
    "c = tf.Variable([12.3-4.85j, 7.5-6.12j], tf.complex64)\n",
    "\n",
    "print(a.numpy())\n",
    "print(a.dtype)\n",
    "print(b.numpy())\n",
    "print(c.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# tf.zeors() , tf.rank() : tnesor 차원을 리턴 받기\n",
    "# 배치 * 높이 * 너비 * 색상\n",
    "\n",
    "img = tf.zeros( [10, 299, 299, 3])\n",
    "res = tf.rank(img)\n",
    "\n",
    "print(type(img))\n",
    "print(img)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 요소를 리턴\n",
    "abc = tf.Variable( [1,2,3,4] )\n",
    "abc_1 = abc[2]\n",
    "\n",
    "print(abc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n",
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# tf의 객체를 Variable로 연동\n",
    "\n",
    "my_val = tf.Variable( tf.zeros(2,3,4) ) # 변수\n",
    "print(my_val.numpy())\n",
    "\n",
    "my_val_2 = tf.constant( tf.zeros(2,2,3) ) # 상수\n",
    "print(my_val_2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.0>\n",
      "2.0\n",
      "tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 변수 자동 변환\n",
    "v = tf.Variable(0.0)\n",
    "v.numpy()\n",
    "\n",
    "# w는 v값 기준으로 계산되는 tf.Tensor\n",
    "# 변수가 수식으로 사용하게 되면 tf.Tensor로 변환됨\n",
    "w = v + 1  \n",
    "w\n",
    "\n",
    "a = tf.Variable(1.0)\n",
    "a.assign_add(1)\n",
    "print(a)\n",
    "print(a.numpy())\n",
    "print(a.read_value())  # 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서 = 스칼라 또는 벡터 또는 매트릭스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]]\n",
      "\n",
      "\n",
      "[[-1. -2.]\n",
      " [-3. -4.]\n",
      " [-5. -6.]]\n",
      "\n",
      "\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "\n",
      "\n",
      "[[-0.0532045  -0.08467827]\n",
      " [-0.00690944 -0.02565944]\n",
      " [-0.05182331  0.13943648]]\n",
      "<dtype: 'float32'>\n",
      "\n",
      " [[-0.17129326  2.7399054 ]\n",
      " [-0.36470127  2.5724883 ]\n",
      " [ 1.7593684   0.04449368]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 3*2행의 float32값을 이용해서 값을 구현해보자\n",
    "'''\n",
    "1  2\n",
    "3  4\n",
    "5  6\n",
    "'''\n",
    "a = tf.Variable([[1,2],[3,4],[5,6]], dtype=tf.float32)\n",
    "print(a.numpy())\n",
    "print('\\n')\n",
    "\n",
    "# 전체 -값으로 변경해보자\n",
    "a.assign([[-1,-2],[-3,-4],[-5,-6]])\n",
    "print(a.numpy())\n",
    "print('\\n')\n",
    "\n",
    "# 3*2 행의 값을 모두 0으로 초기화 float32\n",
    "a = tf.Variable(tf.zeros([3,2]), dtype=tf.float32)\n",
    "print(a.numpy())\n",
    "print('\\n')\n",
    "\n",
    "# 3*2 행 값의 요소 모두를 평균은 0, 표준편차는 0.1의 정규난수로 초기화 시키자\n",
    "# tf.random.normal()\n",
    "a = tf.random.normal((3,2), mean=0, stddev=0.1)\n",
    "print(a.numpy())\n",
    "print(a.dtype)\n",
    "\n",
    "# 3*2 행 값의 요소를 모두 -1 ~3 까지의 범위의 균일값을 난수로 초기화 시키자\n",
    "a = tf.random.uniform((3,2), minval= -1, maxval=3)\n",
    "print('\\n',a.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.        0.6931472 1.0986123]\n",
      "[0.7310586  0.8807971  0.95257413]\n",
      "[0.7615942 0.9640276 0.9950547]\n"
     ]
    }
   ],
   "source": [
    "# f(x) 표현하는 연산 시스템\n",
    "# log(x), exp(x), sin(x), cos(x), sigmoid(x), tanh(x) 등\n",
    "\n",
    "a = tf.constant([1,2,3], tf.float32)\n",
    "b = tf.math.log(a)\n",
    "print(b.numpy())\n",
    "\n",
    "c = tf.math.sigmoid(a)\n",
    "print(c.numpy())\n",
    "\n",
    "d = tf.math.tanh(a)\n",
    "print(d.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## softmax : 로지스틱 함수를 다차원으로 만든것\n",
    "- 다항 로지스틱 회귀로 출력에 대한 확률분포 네트워크 출력을 하는 정규화\n",
    "- 신경망의 활성화 함수로 자주 사용한다.\n",
    "- z = K로 실수값을 벡터로 받아서 입력 숫자에 지수에 비례하는 K개의 확률분포 정규화 시킨것\n",
    "\n",
    "\n",
    "- tf.nn.softmax(logits, axis, name)\n",
    "- softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis)\n",
    "\n",
    "< tf.nn.softmax(x) >\n",
    "\n",
    "입력 인수 x : 텐서, 정수 상수 텐서, 변수 상수\n",
    "\n",
    "출력 값 : \n",
    "1. x의 각 요소마다 exp()을 계산해서 A에 할당\n",
    "2. A의 요소를 모두 더해서 임의 변수 a에 넣는다\n",
    "3. A의 요소를 a로 나누어서 출력 텐서를 한다\n",
    "4. 출력 텐서 각 요소의 값은 확률을 나타낸다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09003057 0.24472848 0.66524094]\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1,2,3], tf.float32)\n",
    "b = tf.nn.softmax(a)\n",
    "print(b.numpy()) # 확률분포\n",
    "\n",
    "b = tf.reduce_sum(a)\n",
    "print(b.numpy()) # 확률분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([20. 36.], shape=(2,), dtype=float32) <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "[20. 36.]\n"
     ]
    }
   ],
   "source": [
    "# 사용자 오퍼레이션(노드) 만들기\n",
    "'''\n",
    "@tf.function\n",
    "def 함수명():\n",
    "    연산\n",
    "    return\n",
    "'''\n",
    "\n",
    "# (a+b)*c  - myOP(a,b,c)\n",
    "@tf.function\n",
    "def myOP(a,b,c):\n",
    "    t = tf.math.add(a,b)\n",
    "    return tf.math.multiply(t,c)\n",
    "\n",
    "A = tf.constant( [1,2], tf.float32 )\n",
    "B = tf.constant( [3,4], tf.float32 )\n",
    "C = tf.constant( [5,6], tf.float32 )\n",
    "D = myOP(A,B,C)  \n",
    "print(D, type(D))  # tf.Tensor([20. 36.], shape=(2,), dtype=float32)\n",
    "print(D.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=10.0>, <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.0>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=1>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=2>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=3>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=4>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=5>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=6>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=7>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=8>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=9>)\n",
      "\n",
      "<__main__.MyModuleOne object at 0x000002636B5BD700>\n",
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=10.0>\n"
     ]
    }
   ],
   "source": [
    "# 사용자 자료형 만들기\n",
    "# tf.Module 상속 받아 구현\n",
    "# tf.Module 인스턴스는 Variable을 포함해서 다른 모듈들을 탐색할 수 있다.\n",
    "# trainable_variables = 훈련 가능한 변수를 리턴\n",
    "\n",
    "class MyModuleOne(tf.Module):\n",
    "    def __init__(self):\n",
    "        self.VO = tf.Variable(1.0)\n",
    "        self.VS = [ tf.Variable(x) for x in range(10) ]\n",
    "        \n",
    "class MyOtherModule(tf.Module):\n",
    "    def __init__(self):\n",
    "        self.m = MyModuleOne()\n",
    "        self.v = tf.Variable(10.0)\n",
    "        \n",
    "m = MyOtherModule()\n",
    "print(len(m.variables))\n",
    "print(m.variables)\n",
    "print()\n",
    "print(m.m)  # 11은 m.m에서 다른 값은 m.v에서\n",
    "print(m.v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000002636B68D2E0>\n"
     ]
    }
   ],
   "source": [
    "# 케라스\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential( \n",
    "    [\n",
    "        layers.Dense(2, activation=\"relu\", name=\"layer1\"),\n",
    "        layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(4, name=\"layer3\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer0 (Dense)               (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101,121\n",
      "Trainable params: 101,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "<class 'tensorflow.python.keras.layers.core.Dense'>\n",
      "layer0\n",
      "{'layer0': 0, 'layer1': 1, 'layer2': 2}\n",
      "0\n",
      "['layer0', 'layer1', 'layer2']\n"
     ]
    }
   ],
   "source": [
    "# 순차모델 만들기\n",
    "import tensorflow as tf\n",
    "\n",
    "model = keras.Sequential( \n",
    "    [\n",
    "        layers.Dense(100, name=\"layer0\", input_shape=(1000,)),\n",
    "        layers.Dense(10, name=\"layer1\"),\n",
    "        layers.Dense(1, name=\"layer2\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "print('\\n')\n",
    "print(type(model.layers[0]))\n",
    "print(model.layers[0].name)\n",
    "\n",
    "d = {k.name : i for i, k in enumerate(model.layers)}\n",
    "print(d)\n",
    "print(d['layer0'])\n",
    "\n",
    "layer_name = [k.name for k in model.layers]\n",
    "print(layer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "심층 신경망은 학습한 모든 변환을 수치 데이터 텐서에 적용하는 텐서 연산을 사용한다.\n",
    "\n",
    "  ex) 텐서 덧셈, 텐서 곱셈\n",
    "    \n",
    "tf.keras.layers.Dense(1, name='Layer_2')  -> 신경망을 만들었다. 층을 설정했다.\n",
    "\n",
    "데이터 -> 학습 구조 모델링 -> 학습 수행 -> 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5] [ 3  5  7  9 11]\n"
     ]
    }
   ],
   "source": [
    "# 간단한 공식을 이용하여 값을 전달 후 평가로 예측 값을 구현\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "\n",
    "# y= ax + b\n",
    "# 5 = a2 + b3 = a1 + b7 = a*3 + b\n",
    "\n",
    "# 데이터 지정\n",
    "x = np.array([1,2,3,4,5])\n",
    "y = x*2+1\n",
    "print(x, y)\n",
    "\n",
    "# 학습 구조 모델링\n",
    "model = Sequential() # 레이어를 층층이 쌓아주는 메소드\n",
    "model.add(Dense(1, input_shape = (1,))) # 1개 쌓기\n",
    "\n",
    "# SGD (Stochastic gradient descent : 확률적 경사 하강법)\n",
    "# mes (Mean Squared Error : 평균 제곱 오차)\n",
    "model.compile('SGD','mse') # 이 방법으로 학습\n",
    "\n",
    "# 학습 수행 : 몇 번을 어떻게 할 것인가?\n",
    "model.fit( x,y, epochs=1000, verbose=0 ) # epochs -> 학습 횟수, 학습을 많이 할 수록 predict에서 y값과 가까운 값을 리턴\n",
    "\n",
    "# 평가\n",
    "print('y : ', y, '\\n'\n",
    "      ,'predict : ', model.predict(x).flatten() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(8.0, shape=(), dtype=float32)\n",
      "tf.Tensor(8.0, shape=(), dtype=float32)\n",
      "tf.Tensor(8.0, shape=(), dtype=float32)\n",
      "tf.Tensor(8.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# tf.GradientTape API : 텐서플로는 자동 미분하는 API를 제공\n",
    "# context 안에 실행된 모든 연산을 tape에 기록한다\n",
    "# 후진방식 자동 미분을 사용해서 tape에 기록된 연산 결과를 계산한다\n",
    "# 기울기를 구하는 클래스 : 정밀한 예측 모델을 만들려면 적당히 선택한 매개 변수에서\n",
    "# 예상한 값과 실제 결과를 비교해서 가능한 차이가 적게 매개 변수를 조정하게 된다.\n",
    "# 이때 필요한 것이 GradientTape\n",
    "\n",
    "x = tf.ones((2,2))\n",
    "\n",
    "with tf.GradientTape() as t :\n",
    "    t.watch(x)\n",
    "    y = tf.reduce_sum(x)\n",
    "    z = tf.multiply(y,y)\n",
    "    \n",
    "dz_dx = t.gradient(z,x) # 입력텐서 x에 대한 z값\n",
    "for i in [0,1] :\n",
    "    for j in [0,1]:\n",
    "        assert dz_dx[i][j] == 8.0\n",
    "#         dz_dx[i][j].numpy() == 8.0 # 위와 동일 결과\n",
    "        print(dz_dx[i][j])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
